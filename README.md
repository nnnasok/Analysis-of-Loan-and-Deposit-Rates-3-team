## Краткое описание

Сервис по сбору, хранению и анализу ставок по кредитам и вкладам с агрегатора banki.ru. Включает ETL-пайплайн для ежедневного сбора данных и аналитический модуль для прогнозирования кредитных ставок с использованием моделей ARIMA и SARIMA.

## Содержимое репозитория — основные директории

- `etl/` — ETL-пайплайн для сбора данных (extract, transform, load)
- `parsers/` — парсеры для кредитов, вкладов и регионов
- `storage/` — хранилище сырых данных и истории
- `time_series/` — анализ и прогнозирование временных рядов (ARIMA/SARIMA)
- `utils/` — вспомогательные утилиты
- `.github/workflows/` — GitHub Actions для автоматизации

## Парсинг данных с banki.ru
На данный момент представлен ETL-пайплайн для сбора данных ставок по кредитам и вкладам, доступным в 100 городах РФ. Данные собираются с агрегатора banki.ru и после обработки передаются на удаленную БД.
## Архитектура / схема работы
Структура проекта:
```bash
├── *config.py*
├── etl
│   ├── *db_writer.py*
│   ├── *extract.py*
│   ├── load.py
│   ├── *transform.py*
│   ├── *transform_all.py*
├── ***main.py***
├── parsers
│   ├── *credits_parser_b.py*
│   ├── *deposits_parser_b.py*
│   ├── *regions_parser_b.py*
├── *requirements.txt*
├── storage
│   ├── data_raw
│   ├── history
├── utils
```
Файл ***main.py*** запускает процесс сбора данных - функцию /etl/extract.py/collect_new_data, которая вначале собирает данные об актуальных регионах и их идентификаторов, после чего для каждого региона запускает *credits_parser_b.py* и *deposits_parser_b.py*. Для каждого региона данные на этом этапе сохраняются в
```bash
── data_raw
│   ├── credits
│   │   ├── 103
│   │   │   ├── banki_credits_dump_2025-11-17.csv
│   │   │   └── banki_credits_dump__2025-11-16.csv
│   ├── deposits
│   │   ├── 103
│   │   │   ├── banki_deposits_dump_2025-11-17.csv
│   │   │   └── banki_deposits_dump__2025-11-16.csv
```
Т.е. в /storage/data_raw/{credits or deposits}/{region_id}/banki_{credits or deposits}_ {timestamp}.csv
После сбора в main.py запускается функция transform_all(), которая создает единую базу предложений, добавляет хэш поле для каждого, актуализирует данные через [SCD type 2]([Версионность и история данных / Хабр](https://habr.com/ru/articles/101544/?ysclid=mi51d6rc11997408535)) и делает дополнительные преобразования данных. После чего имеем 5 файлов в /storage/history
```bash
├── credits_products_history.csv
├── credits_regions_history.csv
├── deposits_products_history.csv
├── deposits_regions_history.csv
└── regions.csv
```
Первые два - набор всех существовавших (и существующих) предложений, 3 и 4 - таблицы регион-предложения (один кредит может быть доступен для нескольких регионов и несколько кредитов - для одного региона). В завершении этапа transform_all запускает функцию cleanup_raw(), удаляющую все raw файлы старше 3х дней (все данные с них уже перенесены в /history и бд, потребность в них отпадает).

Далее в main.py вызывается DBWriter().run_all() - подключение к удаленной БД (используем [Neon](https://console.neon.tech/)) и сохранение данных в 6 таблиц: banks, regions, credit_products, credit_regions, deposit_products, deposit_regions. Ознакомиться подробнее со столбцами и типами значений в них можно в etl/db_writer.py (def \_\_init__())

## Установка и запуск
```python
pip install -r requirements.txt
python main.py
```
Также необходимы .env переменные, импортируемые в программу: данные подключения к базе данных и куки.
## Как работает GitHub Actions
GH actions запускает main.py ежедневно в 13:00 по мск, по выполнении - пушит новые файлы в репозиторий и отправляет в neon db. Время работы зависит от скорости парсинга (частое падение подключения к сайту приводит к долгим паузам) и в среднем занимает от 60-100 минут.

# Прогнозирование кредитных ставок с помощью моделей ARIMA и SARIMA

**Исходные данные** по кредитным ставкам содержатся в файле `loans_ind.xlsx`. Файл взят с сайта ЦБР.

### Временные ряды
В файле с обработанными данными `processed_data.csv` представлены 7 временных рядов:
- `rate_30` - ставки по кредитам до 30 дней
- `rate_31_90` - ставки по кредитам от 31 до 90 дней
- `rate_91_180` - ставки по кредитам от 91 до 180 дней
- `rate_181_1` - ставки по кредитам от 181 дня до 1 года
- `rate_1` - ставки по кредитам до 1 года
- `rate_1_3` - ставки по кредитам от 1 года до 3 лет
- `rate_3` - ставки по кредитам от 3 лет

Каждый ряд состоит из 140 месячных наблюдений

## Модели прогнозирования
1. **ARIMA (AutoRegressive Integrated Moving Average)**  
   Модель эффективно работает с трендами за счет основных компонент:
- **AR (Авторегрессия)** - учитывает влияние прошлых значений ряда на будущие
- **I (Интегрирование)** - преобразует нестационарный ряд в стационарный через дифференцирование (вычитание из i-го значения ряда i-1-го)
- **MA (Скользящее среднее)** - учитывает влияние прошлых ошибок прогноза на будущие значения

2. **SARIMA (Seasonal ARIMA)**  
   Это расширение ARIMA, которое дополнительно учитывает сезонные паттерны.
- **Сезонная авторегрессия** - учитывает влияние значений годовой давности
- **Сезонное дифференцирование** - убирает сезонные тренды (т.е. из i-го значения ряда уже вычитается i-s)
- **Сезонное скользящее среднее** - учитывает сезонные ошибки прогноза

### Процесс анализа
1. **Предобработка данных** - проверка стационарности ряда
2. **Подбор параметров** - автоматический выбор оптимальных (p,d,q) и (P,D,Q,s) параметров
3. **Построение моделей** - обучение ARIMA и SARIMA моделей
4. **Валидация** - оценка качества прогнозов
5. **Визуализация** - графики фактических и прогнозных значений

## Файлы проекта

### Основные файлы
**`credit_rates.ipynb`** - основной Jupyter Notebook с полным анализом  
**`loans_ind.xlsx`** - исходные данные Excel  
**`processed_data.csv`** - обработанные данные CSV  

### Результаты прогнозирования
**`arima_3.csv`** - прогнозы ARIMA на 3 месяца вперед  
**`arima_6.csv`** - прогнозы ARIMA на 6 месяцев вперед  
**`sarima_3.csv`** - прогнозы SARIMA на 3 месяца вперед  
**`sarima_6.csv`** - прогнозы SARIMA на 6 месяцев вперед

## Быстрый старт

### Для запуска в Google Colab:
1. Откройте [Google Colab](https://colab.research.google.com/)
2. Загрузите файл `credit_rates.ipynb`
3. Загрузите файл данных `loans_ind.xlsx`
4. Запустите все ячейки ноутбука

### Для локального запуска:
```bash
jupyter notebook credit_rates.ipynb
